#!/usr/bin/env python3
"""
æ ‘è“æ´¾ç™¾åº¦é¦–é¡µæ–°é—»æ¨é€è„šæœ¬
ä½œè€…ï¼šé»„ç£Š
åŠŸèƒ½ï¼šæ¯æ—¥å®šæ—¶æ¨é€ç™¾åº¦é¦–é¡µæ–°é—»åˆ°é‚®ç®±
"""

import smtplib
import requests
import json
import time
import re
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime
import logging
import os
from typing import List, Dict
from bs4 import BeautifulSoup

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/var/log/baidu_homepage_news.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class BaiduHomepageNewsCollector:
    """ç™¾åº¦é¦–é¡µæ–°é—»æ”¶é›†å™¨"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'DNT': '1',
            'Connection': 'keep-alive',
        }
    
    def fetch_baidu_homepage_news(self) -> List[Dict]:
        """è·å–ç™¾åº¦é¦–é¡µæ–°é—»ï¼ˆå‰10æ¡ï¼‰"""
        news_items = []
        
        try:
            logger.info("æ­£åœ¨æŠ“å–ç™¾åº¦é¦–é¡µ(www.baidu.com)æ–°é—»...")
            
            # è·å–ç™¾åº¦é¦–é¡µ
            url = "https://www.baidu.com/"
            response = requests.get(url, headers=self.headers, timeout=10)
            response.encoding = 'utf-8'
            
            # ä¿å­˜HTMLç”¨äºè°ƒè¯•
            with open("/tmp/baidu_homepage.html", "w", encoding="utf-8") as f:
                f.write(response.text)
            logger.info("âœ“ å·²ä¿å­˜ç™¾åº¦é¦–é¡µHTMLåˆ° /tmp/baidu_homepage.html")
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æ–¹æ³•1ï¼šæŸ¥æ‰¾ç™¾åº¦é¦–é¡µçš„çƒ­ç‚¹æ–°é—»
            news_items = self._parse_hot_news(soup)
            
            # æ–¹æ³•2ï¼šå¦‚æœçƒ­ç‚¹æ–°é—»æ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾æ‰€æœ‰æ–°é—»é“¾æ¥
            if len(news_items) < 5:
                logger.info("çƒ­ç‚¹æ–°é—»è·å–è¾ƒå°‘ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•...")
                backup_items = self._parse_all_news_links(soup)
                news_items.extend(backup_items)
            
            # æ–¹æ³•3ï¼šå°è¯•è§£æç™¾åº¦çƒ­æœæ¦œ
            if len(news_items) < 5:
                logger.info("å°è¯•è§£æçƒ­æœæ¦œ...")
                hotsearch_items = self._parse_hotsearch(soup)
                news_items.extend(hotsearch_items)
            
            # å»é‡å¹¶é™åˆ¶æ•°é‡
            seen_titles = set()
            unique_news = []
            
            for news in news_items:
                if news['title'] and news['title'] not in seen_titles:
                    seen_titles.add(news['title'])
                    unique_news.append(news)
                if len(unique_news) >= 10:
                    break
            
            logger.info(f"æˆåŠŸæ”¶é›†åˆ° {len(unique_news)} æ¡ç™¾åº¦é¦–é¡µæ–°é—»")
            return unique_news[:10]
            
        except Exception as e:
            logger.error(f"è·å–ç™¾åº¦é¦–é¡µæ–°é—»å¤±è´¥: {e}")
            # è¿”å›ç¤ºä¾‹æ•°æ®ä½œä¸ºå¤‡ä»½
            return self._get_backup_news()
    
    def _parse_hot_news(self, soup) -> List[Dict]:
        """è§£æç™¾åº¦é¦–é¡µçƒ­ç‚¹æ–°é—»"""
        news_list = []
        
        try:
            # ç™¾åº¦é¦–é¡µçƒ­ç‚¹æ–°é—»é€šå¸¸åœ¨è¿™äº›ä½ç½®
            hot_selectors = [
                '#hotsearch-content-wrapper .hotsearch-item',  # çƒ­ç‚¹æ–°é—»é¡¹
                '.s-hotsearch-title',                          # çƒ­æœæ ‡é¢˜
                '.hot-title',                                   # çƒ­ç‚¹æ ‡é¢˜
                '[class*="hot"] a',                            # åŒ…å«hotçš„ç±»
                '[class*="news"] a',                           # åŒ…å«newsçš„ç±»
            ]
            
            for selector in hot_selectors:
                items = soup.select(selector)
                logger.info(f"çƒ­ç‚¹é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(items)} ä¸ªå…ƒç´ ")
                
                for item in items[:10]:
                    try:
                        title = self._clean_title(item.text)
                        if not title or len(title) < 3:
                            continue
                        
                        link = self._fix_link(item.get('href', ''))
                        
                        news_list.append({
                            'title': title,
                            'link': link,
                            'summary': 'ç™¾åº¦çƒ­ç‚¹æ–°é—»',
                            'source': 'ç™¾åº¦é¦–é¡µ',
                            'type': 'çƒ­ç‚¹'
                        })
                        
                    except Exception as e:
                        logger.debug(f"è§£æçƒ­ç‚¹æ–°é—»å¤±è´¥: {e}")
                        continue
                
                if news_list:
                    break
            
            return news_list
            
        except Exception as e:
            logger.error(f"è§£æçƒ­ç‚¹æ–°é—»å¤±è´¥: {e}")
            return []
    
    def _parse_hotsearch(self, soup) -> List[Dict]:
        """è§£æç™¾åº¦çƒ­æœæ¦œ"""
        news_list = []
        
        try:
            # æŸ¥æ‰¾çƒ­æœæ¦œç›¸å…³å…ƒç´ 
            hotsearch_selectors = [
                '.hotsearch-item',
                '.s-news-rank-content .title-content',
                '[class*="rank"]',
                '[class*="hotsearch"]',
            ]
            
            for selector in hotsearch_selectors:
                items = soup.select(selector)
                logger.info(f"çƒ­æœé€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(items)} ä¸ªå…ƒç´ ")
                
                for item in items[:15]:
                    try:
                        title = self._clean_title(item.text)
                        if not title or len(title) < 3:
                            continue
                        
                        # æŸ¥æ‰¾é“¾æ¥
                        link_tag = item.find('a')
                        link = self._fix_link(link_tag.get('href', '')) if link_tag else ""
                        
                        if not link:
                            link = f"https://www.baidu.com/s?wd={requests.utils.quote(title)}"
                        
                        news_list.append({
                            'title': title,
                            'link': link,
                            'summary': 'ç™¾åº¦çƒ­æœ',
                            'source': 'ç™¾åº¦çƒ­æœæ¦œ',
                            'type': 'çƒ­æœ'
                        })
                        
                    except Exception as e:
                        logger.debug(f"è§£æçƒ­æœé¡¹å¤±è´¥: {e}")
                        continue
                
                if len(news_list) >= 5:
                    break
            
            return news_list
            
        except Exception as e:
            logger.error(f"è§£æçƒ­æœæ¦œå¤±è´¥: {e}")
            return []
    
    def _parse_all_news_links(self, soup) -> List[Dict]:
        """è§£ææ‰€æœ‰å¯èƒ½çš„æ–°é—»é“¾æ¥"""
        news_list = []
        
        try:
            # æŸ¥æ‰¾æ‰€æœ‰é“¾æ¥
            all_links = soup.find_all('a', href=True)
            logger.info(f"æ‰¾åˆ° {len(all_links)} ä¸ªé“¾æ¥")
            
            news_keywords = [
                'æ–°é—»', 'æŠ¥é“', 'æ¶ˆæ¯', 'èµ„è®¯', 'çƒ­ç‚¹', 'æœ€æ–°', 'ä»Šæ—¥',
                'ç–«æƒ…', 'æ”¿ç­–', 'ç»æµ', 'ç§‘æŠ€', 'ä½“è‚²', 'å¨±ä¹', 'è´¢ç»'
            ]
            
            for link in all_links:
                try:
                    title = self._clean_title(link.text)
                    if not title or len(title) < 5 or len(title) > 100:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ–°é—»å…³é”®è¯
                    has_news_keyword = any(keyword in title for keyword in news_keywords)
                    if not has_news_keyword:
                        continue
                    
                    href = link.get('href', '')
                    if not href or href == '#' or href.startswith('javascript'):
                        continue
                    
                    link_url = self._fix_link(href)
                    
                    news_list.append({
                        'title': title,
                        'link': link_url,
                        'summary': 'ç™¾åº¦é¦–é¡µèµ„è®¯',
                        'source': 'ç™¾åº¦',
                        'type': 'èµ„è®¯'
                    })
                    
                    if len(news_list) >= 15:
                        break
                        
                except Exception as e:
                    continue
            
            return news_list
            
        except Exception as e:
            logger.error(f"è§£ææ‰€æœ‰é“¾æ¥å¤±è´¥: {e}")
            return []
    
    def _clean_title(self, title: str) -> str:
        """æ¸…ç†æ ‡é¢˜"""
        if not title:
            return ""
        
        # ç§»é™¤å¤šä½™ç©ºç™½å­—ç¬¦
        title = re.sub(r'\s+', ' ', title.strip())
        
        # è¿‡æ»¤å¤ªçŸ­æˆ–æ— æ•ˆçš„æ ‡é¢˜
        if len(title) < 3:
            return ""
        
        return title
    
    def _fix_link(self, link: str) -> str:
        """ä¿®å¤é“¾æ¥"""
        if not link:
            return "https://www.baidu.com"
        
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if link.startswith('//'):
            return 'https:' + link
        elif link.startswith('/'):
            return 'https://www.baidu.com' + link
        elif not link.startswith('http'):
            return 'https://' + link
        
        return link
    
    def _get_backup_news(self) -> List[Dict]:
        """è·å–å¤‡ç”¨æ–°é—»æ•°æ®"""
        current_time = datetime.now().strftime('%H:%M')
        return [{
            'title': 'ç™¾åº¦é¦–é¡µçƒ­ç‚¹æ–°é—»',
            'link': 'https://www.baidu.com',
            'summary': f'å½“å‰æ—¶é—´ {current_time} çš„é¦–é¡µæ–°é—»',
            'source': 'ç™¾åº¦é¦–é¡µ',
            'type': 'ç¤ºä¾‹'
        }]

class EmailSender:
    """é‚®ä»¶å‘é€å™¨"""
    
    def __init__(self, config_path: str = 'email_config.json'):
        self.config = self._load_config(config_path)
    
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é‚®ä»¶é…ç½®"""
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    logger.info("âœ“ ä»é…ç½®æ–‡ä»¶åŠ è½½é‚®ä»¶é…ç½®")
                    return config
            except Exception as e:
                logger.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        
        # é»˜è®¤é…ç½®
        default_config = {
            "smtp_server": "smtp.qq.com",
            "smtp_port": 465,
            "sender_email": "",
            "sender_password": "",
            "receiver_email": "",
            "use_ssl": True,
            "use_tls": False
        }
        
        logger.warning("âš  ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œè¯·ä¿®æ”¹email_config.json")
        return default_config
    
    def create_email_content(self, news_items: List[Dict]) -> str:
        """åˆ›å»ºé‚®ä»¶å†…å®¹ - ç™¾åº¦é¦–é¡µæ–°é—»ç‰ˆ"""
        current_time = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <style>
                body {{ font-family: "Microsoft YaHei", Arial, sans-serif; line-height: 1.6; color: #333; background-color: #f5f7fa; }}
                .container {{ max-width: 800px; margin: 0 auto; padding: 20px; background-color: white; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
                .header {{ background: linear-gradient(135deg, #2932e1 0%, #1a237e 100%); color: white; padding: 25px; border-radius: 8px; margin-bottom: 25px; text-align: center; }}
                .header h1 {{ margin: 0 0 10px 0; font-size: 28px; }}
                .header p {{ margin: 5px 0; opacity: 0.9; }}
                .news-item {{ border-left: 5px solid #2932e1; padding: 18px; margin-bottom: 18px; background-color: #f8f9fa; border-radius: 0 8px 8px 0; transition: all 0.3s; }}
                .news-item:hover {{ transform: translateX(5px); box-shadow: 0 4px 12px rgba(0,0,0,0.1); }}
                .news-rank {{ display: inline-block; width: 28px; height: 28px; line-height: 28px; text-align: center; background-color: #2932e1; color: white; border-radius: 50%; font-weight: bold; margin-right: 12px; }}
                .news-title {{ display: inline-block; font-size: 18px; font-weight: bold; margin-bottom: 10px; color: #2c3e50; }}
                .news-meta {{ color: #666; font-size: 14px; margin-bottom: 8px; }}
                .news-type {{ display: inline-block; background-color: #ff6b6b; color: white; padding: 2px 8px; border-radius: 12px; font-size: 12px; margin-left: 10px; }}
                .news-summary {{ color: #444; line-height: 1.7; margin-bottom: 12px; }}
                .news-link {{ color: #2932e1; text-decoration: none; font-weight: bold; display: inline-block; margin-top: 8px; }}
                .news-link:hover {{ text-decoration: underline; }}
                .footer {{ margin-top: 40px; padding-top: 20px; border-top: 1px solid #eee; color: #7f8c8d; font-size: 13px; text-align: center; }}
                .baidu-logo {{ color: #2932e1; font-weight: bold; }}
                .time-badge {{ background-color: #e3f2fd; color: #1565c0; padding: 4px 12px; border-radius: 15px; font-size: 14px; display: inline-block; margin-left: 10px; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>ğŸ” ç™¾åº¦é¦–é¡µæ–°é—»æ¨é€</h1>
                    <p>ğŸ“… æ¨é€æ—¶é—´ï¼š{current_time} <span class="time-badge">å®æ—¶æ›´æ–°</span></p>
                    <p>ğŸ“Š ä»Šæ—¥æ–°é—»æ•°é‡ï¼š{len(news_items)}æ¡</p>
                </div>
        """
        
        for i, news in enumerate(news_items, 1):
            type_display = f'<span class="news-type">{news.get("type", "æ–°é—»")}</span>'
            
            html_content += f"""
                <div class="news-item">
                    <span class="news-rank">{i}</span>
                    <div class="news-title">{news.get('title', '')} {type_display}</div>
                    <div class="news-meta">
                        ğŸ“ æ¥æºï¼š<span class="baidu-logo">{news.get('source', 'ç™¾åº¦é¦–é¡µ')}</span>
                    </div>
                    <div class="news-summary">{news.get('summary', '')}</div>
                    <a href="{news.get('link', '#')}" class="news-link" target="_blank">ğŸ“– æŸ¥çœ‹è¯¦æƒ… â†’</a>
                </div>
            """
        
        html_content += f"""
                <div class="footer">
                    <p>æœ¬é‚®ä»¶ç”±é»„ç£Šçš„æ ‘è“æ´¾è‡ªåŠ¨å‘é€ | æ•°æ®æ¥æºï¼šç™¾åº¦é¦–é¡µ(www.baidu.com)</p>
                    <p>å‘é€æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æŠ€æœ¯æ”¯æŒï¼šæ ‘è“æ´¾4B</p>
                    <p>ğŸ’¡ ç™¾åº¦é¦–é¡µå®æ—¶æ›´æ–°ï¼Œåæ˜ å½“å‰æœ€å—å…³æ³¨çš„æ–°é—»äº‹ä»¶</p>
                </div>
            </div>
        </body>
        </html>
        """
        
        return html_content
    
    def send_email_with_retry(self, subject: str, html_content: str, max_retries: int = 3) -> bool:
        """å‘é€é‚®ä»¶ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
        for attempt in range(max_retries):
            try:
                logger.info(f"å°è¯•å‘é€é‚®ä»¶ (ç¬¬{attempt+1}æ¬¡å°è¯•)")
                
                # æ£€æŸ¥é…ç½®
                if not all([self.config.get('sender_email'), 
                          self.config.get('sender_password'), 
                          self.config.get('receiver_email')]):
                    logger.error("âŒ é‚®ç®±é…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥email_config.json")
                    return False
                
                # åˆ›å»ºé‚®ä»¶
                msg = MIMEMultipart('alternative')
                msg['Subject'] = subject
                msg['From'] = self.config['sender_email']
                msg['To'] = self.config['receiver_email']
                
                # æ·»åŠ HTMLå†…å®¹
                html_part = MIMEText(html_content, 'html', 'utf-8')
                msg.attach(html_part)
                
                # æ ¹æ®é…ç½®é€‰æ‹©è¿æ¥æ–¹å¼
                smtp_server = self.config['smtp_server']
                smtp_port = int(self.config.get('smtp_port', 465))
                use_ssl = self.config.get('use_ssl', False)
                use_tls = self.config.get('use_tls', False)
                
                logger.info(f"è¿æ¥åˆ° {smtp_server}:{smtp_port} (SSL:{use_ssl}, TLS:{use_tls})")
                
                # è¿æ¥æœåŠ¡å™¨
                if use_ssl:
                    server = smtplib.SMTP_SSL(smtp_server, smtp_port, timeout=30)
                else:
                    server = smtplib.SMTP(smtp_server, smtp_port, timeout=30)
                    server.ehlo()
                    if use_tls:
                        server.starttls()
                        server.ehlo()
                
                # ç™»å½•
                server.login(self.config['sender_email'], self.config['sender_password'])
                
                # å‘é€é‚®ä»¶
                server.send_message(msg)
                server.quit()
                
                logger.info(f"âœ… é‚®ä»¶å‘é€æˆåŠŸ (ç¬¬{attempt+1}æ¬¡å°è¯•)")
                return True
                
            except smtplib.SMTPAuthenticationError as e:
                logger.error(f"âŒ é‚®ç®±è®¤è¯å¤±è´¥: {e}")
                logger.error("è¯·æ£€æŸ¥ï¼š1.é‚®ç®±æ˜¯å¦æ­£ç¡® 2.æ˜¯å¦ä½¿ç”¨æˆæƒç (éå¯†ç ) 3.æ˜¯å¦å¼€å¯SMTPæœåŠ¡")
                return False
                
            except Exception as e:
                logger.error(f"âŒ å‘é€å¤±è´¥ (å°è¯•{attempt+1}/{max_retries}): {type(e).__name__}: {str(e)[:100]}")
                
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 3
                    logger.info(f"ç­‰å¾…{wait_time}ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
        
        logger.error(f"âŒ é‚®ä»¶å‘é€å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("ğŸ” ç™¾åº¦é¦–é¡µæ–°é—»æ¨é€ä»»åŠ¡å¼€å§‹æ‰§è¡Œ")
    
    try:
        # æ£€æŸ¥ç½‘ç»œè¿æ¥
        logger.info("æ£€æŸ¥ç½‘ç»œè¿æ¥...")
        try:
            response = requests.get("https://www.baidu.com", timeout=5)
            logger.info(f"âœ“ ç½‘ç»œè¿æ¥æ­£å¸¸ (çŠ¶æ€ç : {response.status_code})")
        except Exception as e:
            logger.warning(f"âš  ç½‘ç»œè¿æ¥å¯èƒ½æœ‰é—®é¢˜: {e}")
        
        # æ”¶é›†æ–°é—»
        news_collector = BaiduHomepageNewsCollector()
        news_items = news_collector.fetch_baidu_homepage_news()
        
        if not news_items:
            logger.error("âŒ æœªèƒ½è·å–åˆ°æ–°é—»")
            return False
        
        logger.info(f"âœ… æˆåŠŸæ”¶é›†åˆ° {len(news_items)} æ¡ç™¾åº¦é¦–é¡µæ–°é—»")
        
        # æ˜¾ç¤ºæ–°é—»æ ‡é¢˜ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        for i, news in enumerate(news_items, 1):
            logger.info(f"{i:2d}. {news['title']}")
        
        # åˆ›å»ºé‚®ä»¶å†…å®¹
        email_sender = EmailSender()
        current_date = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        subject = f"ğŸ” ç™¾åº¦é¦–é¡µæ–°é—»TOP{len(news_items)} {current_date}"
        
        html_content = email_sender.create_email_content(news_items)
        
        # å‘é€é‚®ä»¶
        success = email_sender.send_email_with_retry(subject, html_content)
        
        if success:
            logger.info("âœ… ç™¾åº¦é¦–é¡µæ–°é—»æ¨é€ä»»åŠ¡å®Œæˆ")
            save_backup(news_items)
        else:
            logger.error("âŒ é‚®ä»¶å‘é€å¤±è´¥ï¼Œä½†æ–°é—»å·²æ”¶é›†")
            save_backup(news_items)
            logger.info("ğŸ“ æ–°é—»å·²ä¿å­˜åˆ°æœ¬åœ°å¤‡ä»½æ–‡ä»¶")
        
        return success
        
    except Exception as e:
        logger.error(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        return False

def save_backup(news_items: List[Dict]):
    """ä¿å­˜æ–°é—»åˆ°æœ¬åœ°å¤‡ä»½æ–‡ä»¶"""
    try:
        backup_dir = "/home/send_news/backups"
        os.makedirs(backup_dir, exist_ok=True)
        
        filename = f"baidu_homepage_news_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        filepath = os.path.join(backup_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"ç™¾åº¦é¦–é¡µæ–°é—»å¤‡ä»½ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 50 + "\n")
            for i, news in enumerate(news_items, 1):
                f.write(f"{i}. {news.get('title', '')}\n")
                f.write(f"   é“¾æ¥: {news.get('link', '')}\n")
                f.write(f"   æ¥æº: {news.get('source', '')}\n")
                f.write("-" * 30 + "\n")
        
        logger.info(f"ğŸ“„ æ–°é—»å¤‡ä»½å·²ä¿å­˜: {filepath}")
    except Exception as e:
        logger.error(f"ä¿å­˜å¤‡ä»½å¤±è´¥: {e}")

if __name__ == "__main__":
    start_time = time.time()
    
    success = main()
    
    elapsed_time = time.time() - start_time
    logger.info(f"â±ï¸ ä»»åŠ¡æ‰§è¡Œè€—æ—¶: {elapsed_time:.2f}ç§’")
    logger.info("=" * 60)
    
    exit(0 if success else 1)